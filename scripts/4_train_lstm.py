"""
è®­ç»ƒLSTMæ¨¡å‹
"""
import sys
from pathlib import Path
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader, random_split
import json
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from emberguard.lstm_model import LSTMFireClassifier, LSTMTrainer


def run_quick_test(lstm_model, device='cpu'):
    """
    å¿«é€Ÿæµ‹è¯•å‡½æ•° - åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è°ƒç”¨
    
    Args:
        lstm_model: LSTMæ¨¡å‹
        device: è®¡ç®—è®¾å¤‡
        
    Returns:
        dict: æµ‹è¯•ç»“æœ
    """
    from pathlib import Path
    import cv2
    import numpy as np
    from emberguard.feature_extractor import FeatureExtractor
    from ultralytics import YOLO
    
    # åŠ è½½YOLOæ¨¡å‹
    yolo_model = YOLO('runs/detect/train2/weights/best.pt')
    feature_extractor = FeatureExtractor()
    
    # æµ‹è¯•å›¾ç‰‡
    test_images = [
        'test_picture/1.png',  # çƒŸé›¾
        'test_picture/2.jpg',  # çƒŸé›¾
        'test_picture/3.jpg',  # ç«ç„°+çƒŸé›¾
        'test_picture/4.jpg'   # ç«ç„°
    ]
    
    # å·²çŸ¥æ ‡ç­¾ï¼ˆæ‰‹åŠ¨æ ‡æ³¨ï¼‰
    # æ ‡æ³¨ç­–ç•¥ï¼šæœ‰ç«ç„°å°±æ ‡è®°ä¸ºç«ç„°(2)ï¼Œåªæœ‰çƒŸé›¾æ ‡è®°ä¸ºçƒŸé›¾(1)
    # è¿™ä¸è®­ç»ƒæ•°æ®çš„æ ‡æ³¨ç­–ç•¥ä¸€è‡´ï¼ˆfireç›®å½•â†’2, smokeç›®å½•â†’1ï¼‰
    true_labels = [1, 1, 2, 2]  # 0=æ— ç«, 1=çƒŸé›¾, 2=ç«ç„°
    
    # æ³¨æ„ï¼šå›¾ç‰‡3æ—¢æœ‰ç«åˆæœ‰çƒŸï¼Œä½†åœ¨å•æ ‡ç­¾ç³»ç»Ÿä¸­åªèƒ½æ ‡è®°ä¸ºç«ç„°(2)
    # è¿™æ˜¯å½“å‰æ¨¡å‹è®¾è®¡çš„å±€é™æ€§ï¼Œæœªæ¥å¯ä»¥æ”¹ä¸ºå¤šæ ‡ç­¾åˆ†ç±»
    
    correct = 0
    total = 0
    confidences = []
    fire_correct = 0
    fire_total = 0
    
    lstm_model.eval()
    
    for img_path, true_label in zip(test_images, true_labels):
        if not Path(img_path).exists():
            continue
        
        # è¯»å–å›¾ç‰‡
        img = cv2.imread(img_path)
        
        # YOLOæ£€æµ‹
        results = yolo_model(img, verbose=False)
        
        # æå–ç‰¹å¾
        features = feature_extractor.get_best_detection(results, img.shape)
        
        # åˆ›å»º30å¸§åºåˆ—
        sequence = np.array([features] * 30)
        
        # LSTMé¢„æµ‹
        with torch.no_grad():
            sequence_tensor = torch.FloatTensor(sequence).unsqueeze(0).to(device)
            outputs = lstm_model(sequence_tensor)
            probs = torch.softmax(outputs, dim=1)
            pred_class = torch.argmax(probs, dim=1).item()
            confidence = probs[0][pred_class].item()
        
        # ç»Ÿè®¡
        total += 1
        if pred_class == true_label:
            correct += 1
        
        confidences.append(confidence)
        
        # ç»Ÿè®¡Fireç±»åˆ«
        if true_label == 2:
            fire_total += 1
            if pred_class == 2:
                fire_correct += 1
    
    lstm_model.train()
    
    return {
        'image_accuracy': 100 * correct / total if total > 0 else 0,
        'fire_correct': fire_correct,
        'fire_total': fire_total,
        'avg_confidence': np.mean(confidences) if confidences else 0,
        'total_tested': total
    }


class FireSequenceDataset(Dataset):
    """ç«ç¾åºåˆ—æ•°æ®é›†"""
    
    def __init__(self, sequences, labels):
        """
        åˆå§‹åŒ–
        
        Args:
            sequences: ç‰¹å¾åºåˆ— (N, seq_len, feature_dim)
            labels: æ ‡ç­¾ (N,)
        """
        self.sequences = torch.FloatTensor(sequences)
        self.labels = torch.LongTensor(labels)
    
    def __len__(self):
        return len(self.sequences)
    
    def __getitem__(self, idx):
        return self.sequences[idx], self.labels[idx]


def load_dataset(data_dir):
    """
    åŠ è½½æ•°æ®é›†
    
    Args:
        data_dir: æ•°æ®ç›®å½•
        
    Returns:
        tuple: (sequences, labels, metadata)
    """
    data_dir = Path(data_dir)
    
    sequences = np.load(data_dir / 'sequences.npy')
    labels = np.load(data_dir / 'labels.npy')
    
    with open(data_dir / 'metadata.json', 'r', encoding='utf-8') as f:
        metadata = json.load(f)
    
    return sequences, labels, metadata


def train_lstm_model(
    data_dir,
    output_dir='models/lstm',
    hidden_size=128,
    num_layers=2,
    dropout=0.3,
    batch_size=32,
    epochs=50,
    learning_rate=0.001,
    val_split=0.2,
    device=None,
    resume=False,
    use_focal_loss=True,
    focal_gamma=2.0,
    test_interval=5
):
    """
    è®­ç»ƒLSTMæ¨¡å‹
    
    Args:
        data_dir: æ•°æ®ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        hidden_size: LSTMéšè—å±‚å¤§å°
        num_layers: LSTMå±‚æ•°
        dropout: Dropoutæ¯”ä¾‹
        batch_size: æ‰¹æ¬¡å¤§å°
        epochs: è®­ç»ƒè½®æ•°
        learning_rate: å­¦ä¹ ç‡
        val_split: éªŒè¯é›†æ¯”ä¾‹
        device: è®¡ç®—è®¾å¤‡
        resume: æ˜¯å¦ä»æ–­ç‚¹ç»§ç»­è®­ç»ƒ
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # è®¾å¤‡
    if device is None:
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ•°æ®
    print("\nåŠ è½½æ•°æ®...")
    sequences, labels, metadata = load_dataset(data_dir)
    
    print(f"æ•°æ®é›†ä¿¡æ¯:")
    print(f"- åºåˆ—æ•°: {len(sequences)}")
    print(f"- åºåˆ—é•¿åº¦: {metadata['sequence_length']}")
    print(f"- ç‰¹å¾ç»´åº¦: {metadata['feature_dim']}")
    print(f"- ç±»åˆ«æ•°: {metadata['num_classes']}")
    print(f"- æ ‡ç­¾åˆ†å¸ƒ: {metadata['label_distribution']}")
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = FireSequenceDataset(sequences, labels)
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    val_size = int(len(dataset) * val_split)
    train_size = len(dataset) - val_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
    
    print(f"\næ•°æ®åˆ’åˆ†:")
    print(f"- è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
    print(f"- éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    
    # è®¡ç®—ç±»åˆ«æƒé‡ï¼ˆå¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼‰
    label_counts = np.array(metadata['label_distribution'])
    total_samples = label_counts.sum()
    class_weights = total_samples / (len(label_counts) * label_counts)
    class_weights = torch.FloatTensor(class_weights).to(device)
    
    print(f"\nç±»åˆ«æƒé‡ï¼ˆå¤„ç†ä¸å¹³è¡¡ï¼‰:")
    for i, (name, count, weight) in enumerate(zip(metadata['class_names'], label_counts, class_weights)):
        print(f"  {name} (æ ‡ç­¾{i}): {count}ä¸ªæ ·æœ¬ ({count/total_samples*100:.1f}%), æƒé‡={weight:.3f}")
    
    # åˆ›å»ºæ¨¡å‹
    print("\nåˆ›å»ºæ¨¡å‹...")
    model = LSTMFireClassifier(
        input_size=metadata['feature_dim'],
        hidden_size=hidden_size,
        num_layers=num_layers,
        num_classes=metadata['num_classes'],
        dropout=dropout
    )
    
    print(f"æ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.parameters())} ä¸ª")
    
    # åˆ›å»ºè®­ç»ƒå™¨ï¼ˆä½¿ç”¨Focal Lossï¼‰
    trainer = LSTMTrainer(model, device=device)
    
    # é€‰æ‹©æŸå¤±å‡½æ•°
    if use_focal_loss:
        # Focal Lossä¼šè‡ªåŠ¨å¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼Œä½†ä»å¯ä»¥ç»“åˆç±»åˆ«æƒé‡
        # è¿™é‡Œä½¿ç”¨è¾ƒå°çš„æƒé‡ï¼Œè®©Focal Losså‘æŒ¥ä¸»è¦ä½œç”¨
        adjusted_weights = torch.FloatTensor([0.8, 1.0, 3.5]).to(device)  # æé«˜Fireæƒé‡åˆ°3.5xï¼Œé™ä½Normalåˆ°0.8x
        trainer.compile(
            learning_rate=learning_rate, 
            class_weights=adjusted_weights,
            use_focal_loss=True,
            focal_gamma=focal_gamma
        )
        print(f"âœ… ä½¿ç”¨Focal Loss (gamma={focal_gamma}) + è°ƒæ•´åçš„ç±»åˆ«æƒé‡")
        print(f"   Normal: 0.8x, Smoke: 1.0x, Fire: 3.5x")
    else:
        # ä¼ ç»ŸåŠ æƒäº¤å‰ç†µ
        trainer.compile(learning_rate=learning_rate, class_weights=class_weights)
        print(f"âœ… ä½¿ç”¨åŠ æƒäº¤å‰ç†µ")
    
    # éªŒè¯trainerå·²æ­£ç¡®åˆå§‹åŒ–
    if trainer.criterion is None or trainer.optimizer is None:
        raise RuntimeError("è®­ç»ƒå™¨åˆå§‹åŒ–å¤±è´¥ï¼šcriterionæˆ–optimizerä¸ºNone")
    
    # æ·»åŠ å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆæ¯10ä¸ªepoché™ä½å­¦ä¹ ç‡ï¼‰
    scheduler = torch.optim.lr_scheduler.StepLR(trainer.optimizer, step_size=10, gamma=0.5)
    print(f"å­¦ä¹ ç‡è°ƒåº¦: æ¯10ä¸ªepoché™ä½50%")
    
    # æ£€æŸ¥æ˜¯å¦ä»æ–­ç‚¹ç»§ç»­
    start_epoch = 0
    best_val_acc = 0
    best_epoch = 0
    history = {
        'train_loss': [],
        'train_acc': [],
        'val_loss': [],
        'val_acc': []
    }
    
    checkpoint_path = output_dir / 'checkpoint.pt'
    if resume and checkpoint_path.exists():
        print(f"\nä»æ–­ç‚¹ç»§ç»­è®­ç»ƒ: {checkpoint_path}")
        checkpoint = torch.load(checkpoint_path, map_location=device)
        
        # æ¢å¤æ¨¡å‹å’Œä¼˜åŒ–å™¨çŠ¶æ€
        trainer.model.load_state_dict(checkpoint['model_state_dict'])
        trainer.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        # æ¢å¤è®­ç»ƒçŠ¶æ€
        start_epoch = checkpoint['epoch'] + 1
        best_val_acc = checkpoint['best_val_acc']
        best_epoch = checkpoint['best_epoch']
        history = checkpoint['history']
        
        # æ£€æŸ¥æŸå¤±å‡½æ•°ä¸€è‡´æ€§
        if 'use_focal_loss' in checkpoint:
            saved_focal = checkpoint['use_focal_loss']
            if saved_focal != use_focal_loss:
                print(f"âš ï¸  è­¦å‘Š: æ–­ç‚¹ä½¿ç”¨çš„æŸå¤±å‡½æ•°ä¸å½“å‰ä¸åŒ")
                print(f"   æ–­ç‚¹: {'Focal Loss' if saved_focal else 'CrossEntropyLoss'}")
                print(f"   å½“å‰: {'Focal Loss' if use_focal_loss else 'CrossEntropyLoss'}")
                print(f"   å°†ä½¿ç”¨å½“å‰è®¾ç½®ç»§ç»­è®­ç»ƒ")
        
        print(f"ä» Epoch {start_epoch} ç»§ç»­è®­ç»ƒ")
        print(f"å½“å‰æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}% (Epoch {best_epoch})")
    else:
        if resume:
            print("\nâš ï¸  æœªæ‰¾åˆ°æ–­ç‚¹æ–‡ä»¶ï¼Œä»å¤´å¼€å§‹è®­ç»ƒ")
    
    # è®­ç»ƒ
    print(f"\nå¼€å§‹è®­ç»ƒ (epochs={start_epoch+1}-{epochs})...")
    print(f"è®¾å¤‡: {device}")
    print(f"æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"å­¦ä¹ ç‡: {learning_rate}")
    print("=" * 60)
    
    # åˆ›å»ºæ—¥å¿—æ–‡ä»¶
    log_file = output_dir / 'training.log'
    log_mode = 'a' if (resume and log_file.exists()) else 'w'
    
    with open(log_file, log_mode, encoding='utf-8') as f:
        if log_mode == 'w':
            f.write(f"EmberGuard AI - LSTMè®­ç»ƒæ—¥å¿—\n")
            f.write(f"{'='*60}\n")
            f.write(f"å¼€å§‹æ—¶é—´: {__import__('datetime').datetime.now()}\n")
            f.write(f"è®¾å¤‡: {device}\n")
            f.write(f"è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬\n")
            f.write(f"éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬\n")
            f.write(f"æ‰¹æ¬¡å¤§å°: {batch_size}\n")
            f.write(f"å­¦ä¹ ç‡: {learning_rate}\n")
            f.write(f"è®­ç»ƒè½®æ•°: {epochs}\n")
            f.write(f"{'='*60}\n\n")
        else:
            f.write(f"\n{'='*60}\n")
            f.write(f"ä»æ–­ç‚¹ç»§ç»­è®­ç»ƒ: {__import__('datetime').datetime.now()}\n")
            f.write(f"ä» Epoch {start_epoch} ç»§ç»­\n")
            f.write(f"{'='*60}\n\n")
    
    import time
    start_time = time.time()
    
    try:
        for epoch in range(start_epoch, epochs):
            epoch_start = time.time()
            
            # è®­ç»ƒï¼ˆæ˜¾ç¤ºè¿›åº¦æ¡ï¼‰
            train_loss, train_acc = trainer.train_epoch(train_loader, show_progress=True)
            
            # éªŒè¯ï¼ˆæ˜¾ç¤ºè¿›åº¦æ¡ï¼‰
            val_loss, val_acc = trainer.validate(val_loader, show_progress=True)
            
            # è®°å½•
            history['train_loss'].append(train_loss)
            history['train_acc'].append(train_acc)
            history['val_loss'].append(val_loss)
            history['val_acc'].append(val_acc)
            
            # è®¡ç®—æ—¶é—´
            epoch_time = time.time() - epoch_start
            elapsed_time = time.time() - start_time
            eta = (elapsed_time / (epoch - start_epoch + 1)) * (epochs - epoch - 1)
            
            # æ›´æ–°å­¦ä¹ ç‡
            current_lr = scheduler.get_last_lr()[0]
            scheduler.step()
            
            # æ‰“å°åˆ°æ§åˆ¶å°
            print(f"Epoch [{epoch+1}/{epochs}] "
                  f"Train Loss: {train_loss:.4f} Acc: {train_acc:.2f}% | "
                  f"Val Loss: {val_loss:.4f} Acc: {val_acc:.2f}% | "
                  f"LR: {current_lr:.6f} | "
                  f"Time: {epoch_time:.1f}s ETA: {eta/60:.1f}min")
            
            # å†™å…¥æ—¥å¿—æ–‡ä»¶
            with open(log_file, 'a', encoding='utf-8') as f:
                f.write(f"Epoch {epoch+1}/{epochs}\n")
                f.write(f"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%\n")
                f.write(f"  Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%\n")
                f.write(f"  LR: {current_lr:.6f}\n")
                f.write(f"  Time: {epoch_time:.1f}s, Elapsed: {elapsed_time/60:.1f}min, ETA: {eta/60:.1f}min\n")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                best_epoch = epoch + 1
                trainer.save_model(output_dir / 'best.pt')
                msg = f"  âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%)"
                print(msg)
                with open(log_file, 'a', encoding='utf-8') as f:
                    f.write(f"  {msg}\n")
            
            # ä¿å­˜æ–­ç‚¹ï¼ˆæ¯ä¸ªepochéƒ½ä¿å­˜ï¼Œç”¨äºæ–­ç‚¹ç»­è®­ï¼‰
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': trainer.model.state_dict(),
                'optimizer_state_dict': trainer.optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'best_val_acc': best_val_acc,
                'best_epoch': best_epoch,
                'history': history,
                'use_focal_loss': use_focal_loss,
                'focal_gamma': focal_gamma if use_focal_loss else None
            }
            torch.save(checkpoint, output_dir / 'checkpoint.pt')
            
            with open(log_file, 'a', encoding='utf-8') as f:
                f.write("\n")
            
            # å®šæœŸæµ‹è¯•
            if test_interval > 0 and (epoch + 1) % test_interval == 0:
                print(f"\n{'='*60}")
                print(f"Epoch {epoch+1} - è¿è¡Œæµ‹è¯•")
                print(f"{'='*60}")
                
                try:
                    # è¿è¡Œå¿«é€Ÿæµ‹è¯•
                    test_results = run_quick_test(lstm_model=trainer.model, device=device)
                    
                    # è®°å½•æµ‹è¯•ç»“æœåˆ°æ—¥å¿—
                    with open(log_file, 'a', encoding='utf-8') as f:
                        f.write(f"  æµ‹è¯•ç»“æœ (Epoch {epoch+1}):\n")
                        f.write(f"    å›¾ç‰‡æµ‹è¯•å‡†ç¡®ç‡: {test_results['image_accuracy']:.1f}%\n")
                        f.write(f"    Fireè¯†åˆ«: {test_results['fire_correct']}/{test_results['fire_total']}\n")
                        f.write(f"    å¹³å‡ç½®ä¿¡åº¦: {test_results['avg_confidence']:.3f}\n")
                        f.write("\n")
                    
                    print(f"âœ… æµ‹è¯•å®Œæˆ - å‡†ç¡®ç‡: {test_results['image_accuracy']:.1f}%")
                    
                except Exception as e:
                    print(f"âš ï¸  æµ‹è¯•å¤±è´¥: {e}")
                    with open(log_file, 'a', encoding='utf-8') as f:
                        f.write(f"  æµ‹è¯•å¤±è´¥: {e}\n\n")
                
                print(f"{'='*60}\n")
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        print(f"å·²ä¿å­˜æ–­ç‚¹åˆ°: {output_dir / 'checkpoint.pt'}")
        print(f"ä½¿ç”¨ --resume å‚æ•°å¯ä»¥ç»§ç»­è®­ç»ƒ")
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(f"\n{'='*60}\n")
            f.write(f"è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­: {__import__('datetime').datetime.now()}\n")
            f.write(f"å·²å®Œæˆ {epoch+1} ä¸ªepoch\n")
            f.write(f"{'='*60}\n")
        return
    
    except Exception as e:
        print(f"\n\nâŒ è®­ç»ƒå‡ºé”™: {e}")
        print(f"å·²ä¿å­˜æ–­ç‚¹åˆ°: {output_dir / 'checkpoint.pt'}")
        print(f"ä½¿ç”¨ --resume å‚æ•°å¯ä»¥ç»§ç»­è®­ç»ƒ")
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(f"\n{'='*60}\n")
            f.write(f"è®­ç»ƒå‡ºé”™: {__import__('datetime').datetime.now()}\n")
            f.write(f"é”™è¯¯ä¿¡æ¯: {e}\n")
            f.write(f"{'='*60}\n")
        raise
    
    total_time = time.time() - start_time
    
    print("=" * 60)
    print(f"\nè®­ç»ƒå®Œæˆ!")
    print(f"æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ ({total_time/3600:.2f} å°æ—¶)")
    print(f"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}% (Epoch {best_epoch})")
    
    # å†™å…¥æœ€ç»ˆç»“æœåˆ°æ—¥å¿—
    with open(log_file, 'a', encoding='utf-8') as f:
        f.write(f"{'='*60}\n")
        f.write(f"è®­ç»ƒå®Œæˆ\n")
        f.write(f"ç»“æŸæ—¶é—´: {__import__('datetime').datetime.now()}\n")
        f.write(f"æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ\n")
        f.write(f"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}% (Epoch {best_epoch})\n")
        f.write(f"{'='*60}\n")
    
    print(f"\nè®­ç»ƒæ—¥å¿—å·²ä¿å­˜: {log_file}")
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    trainer.save_model(output_dir / 'last.pt')
    
    # ä¿å­˜è®­ç»ƒå†å²
    with open(output_dir / 'history.json', 'w') as f:
        json.dump(history, f, indent=2)
    
    # ä¿å­˜è®­ç»ƒé…ç½®
    config = {
        'data_dir': str(data_dir),
        'hidden_size': hidden_size,
        'num_layers': num_layers,
        'dropout': dropout,
        'batch_size': batch_size,
        'epochs': epochs,
        'learning_rate': learning_rate,
        'val_split': val_split,
        'best_val_acc': best_val_acc,
        'best_epoch': best_epoch
    }
    
    with open(output_dir / 'config.json', 'w') as f:
        json.dump(config, f, indent=2)
    
    print(f"\næ¨¡å‹å·²ä¿å­˜åˆ°: {output_dir}")
    print(f"- best.pt: æœ€ä½³æ¨¡å‹")
    print(f"- last.pt: æœ€ç»ˆæ¨¡å‹")
    print(f"- history.json: è®­ç»ƒå†å²")
    print(f"- config.json: è®­ç»ƒé…ç½®")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='è®­ç»ƒLSTMç«ç¾åˆ†ç±»æ¨¡å‹')
    parser.add_argument('--data_dir', type=str, default='datasets/lstm_data',
                       help='æ•°æ®ç›®å½•')
    parser.add_argument('--output_dir', type=str, default='models/lstm',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--hidden_size', type=int, default=128,
                       help='LSTMéšè—å±‚å¤§å°')
    parser.add_argument('--num_layers', type=int, default=2,
                       help='LSTMå±‚æ•°')
    parser.add_argument('--dropout', type=float, default=0.3,
                       help='Dropoutæ¯”ä¾‹')
    parser.add_argument('--batch_size', type=int, default=32,
                       help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--epochs', type=int, default=50,
                       help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--lr', type=float, default=0.001,
                       help='å­¦ä¹ ç‡')
    parser.add_argument('--val_split', type=float, default=0.2,
                       help='éªŒè¯é›†æ¯”ä¾‹')
    parser.add_argument('--device', type=str, default=None,
                       help='è®¡ç®—è®¾å¤‡ (cuda/cpu)')
    parser.add_argument('--resume', action='store_true',
                       help='ä»æ–­ç‚¹ç»§ç»­è®­ç»ƒ')
    parser.add_argument('--use_focal_loss', action='store_true', default=True,
                       help='ä½¿ç”¨Focal Lossï¼ˆé»˜è®¤å¼€å¯ï¼‰')
    parser.add_argument('--focal_gamma', type=float, default=2.5,
                       help='Focal Lossçš„gammaå‚æ•°ï¼ˆé»˜è®¤2.5ï¼Œæé«˜ä»¥æ›´å…³æ³¨éš¾åˆ†ç±»æ ·æœ¬ï¼‰')
    parser.add_argument('--test_interval', type=int, default=5,
                       help='æµ‹è¯•é—´éš”ï¼ˆæ¯Nä¸ªepochæµ‹è¯•ä¸€æ¬¡ï¼Œ0è¡¨ç¤ºä¸æµ‹è¯•ï¼‰')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("LSTMç«ç¾åˆ†ç±»æ¨¡å‹è®­ç»ƒ")
    print("=" * 60)
    
    # è‡ªåŠ¨æ£€æµ‹å¹¶åˆ›å»ºæ–°çš„è®­ç»ƒç›®å½•ï¼ˆç±»ä¼¼YOLOçš„train, train2, train3ï¼‰
    base_output_dir = Path(args.output_dir)
    if base_output_dir.exists() and not args.resume:
        # å¦‚æœç›®å½•å­˜åœ¨ä¸”ä¸æ˜¯ç»§ç»­è®­ç»ƒï¼Œè‡ªåŠ¨åˆ›å»ºæ–°ç›®å½•
        counter = 2
        while True:
            new_output_dir = Path(str(base_output_dir) + str(counter))
            if not new_output_dir.exists():
                args.output_dir = str(new_output_dir)
                print(f"\nğŸ”„ æ£€æµ‹åˆ°å·²æœ‰è®­ç»ƒï¼Œè‡ªåŠ¨åˆ›å»ºæ–°ç›®å½•")
                print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
                break
            counter += 1
    elif args.resume:
        # ç»§ç»­è®­ç»ƒæ—¶ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰checkpoint
        checkpoint_path = base_output_dir / 'checkpoint.pt'
        if checkpoint_path.exists():
            print(f"\nğŸ”„ ä»æ–­ç‚¹ç»§ç»­è®­ç»ƒ")
            print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
        else:
            print(f"\nâš ï¸  æœªæ‰¾åˆ°æ–­ç‚¹æ–‡ä»¶ï¼Œå°†ä»å¤´å¼€å§‹è®­ç»ƒ")
            print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    
    # æ£€æŸ¥æ•°æ®æ˜¯å¦å­˜åœ¨
    data_dir = Path(args.data_dir)
    if not data_dir.exists():
        print(f"\nâŒ é”™è¯¯: æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        print("\nè¯·å…ˆè¿è¡Œ prepare_lstm_data.py å‡†å¤‡è®­ç»ƒæ•°æ®")
        return
    
    # è‡ªåŠ¨æ£€æµ‹æ–­ç‚¹ï¼ˆä»…åœ¨æŒ‡å®šè¾“å‡ºç›®å½•æ—¶ï¼‰
    output_dir = Path(args.output_dir)
    checkpoint_path = output_dir / 'checkpoint.pt'
    
    # å¦‚æœæ˜¯é»˜è®¤ç›®å½•ä¸”å­˜åœ¨checkpointï¼Œè¯¢é—®æ˜¯å¦ç»§ç»­
    if args.output_dir == 'models/lstm' and checkpoint_path.exists() and not args.resume:
        print(f"\nâš ï¸  æ£€æµ‹åˆ°æ–­ç‚¹æ–‡ä»¶: {checkpoint_path}")
        print("æ˜¯å¦ä»æ–­ç‚¹ç»§ç»­è®­ç»ƒï¼Ÿ")
        print("  1. æ˜¯ - ç»§ç»­è®­ç»ƒ")
        print("  2. å¦ - å¼€å§‹æ–°çš„è®­ç»ƒï¼ˆè‡ªåŠ¨åˆ›å»ºtrain2ç›®å½•ï¼‰")
        choice = input("è¯·é€‰æ‹© (1/2): ").strip()
        
        if choice == '1':
            args.resume = True
            print("âœ… å°†ä»æ–­ç‚¹ç»§ç»­è®­ç»ƒ")
        else:
            # è‡ªåŠ¨åˆ›å»ºæ–°ç›®å½•
            counter = 2
            while True:
                new_output_dir = Path(f'models/lstm/train{counter}')
                if not new_output_dir.exists():
                    args.output_dir = str(new_output_dir)
                    print(f"âœ… åˆ›å»ºæ–°è®­ç»ƒç›®å½•: {args.output_dir}")
                    break
                counter += 1
    
    # è®­ç»ƒæ¨¡å‹
    train_lstm_model(
        data_dir=args.data_dir,
        output_dir=args.output_dir,
        hidden_size=args.hidden_size,
        num_layers=args.num_layers,
        dropout=args.dropout,
        batch_size=args.batch_size,
        epochs=args.epochs,
        learning_rate=args.lr,
        val_split=args.val_split,
        device=args.device,
        resume=args.resume,
        use_focal_loss=args.use_focal_loss,
        focal_gamma=args.focal_gamma,
        test_interval=args.test_interval
    )


if __name__ == "__main__":
    main()
