"""
æµ‹è¯•ç‰¹å¾æå–æ•ˆæœ
åœ¨å¼€å§‹å®Œæ•´è®­ç»ƒå‰ï¼Œå…ˆæµ‹è¯•YOLOæ¨¡å‹å’Œç‰¹å¾æå–å™¨
"""
import sys
from pathlib import Path
import cv2
import numpy as np
import random

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from emberguard.feature_extractor import FeatureExtractor
from ultralytics import YOLO


def test_yolo_detection():
    """æµ‹è¯•YOLOæ¨¡å‹æ£€æµ‹æ•ˆæœ - æµ‹è¯•å¤šä¸ªè§†é¢‘"""
    print("=" * 60)
    print("æµ‹è¯•1: YOLOæ¨¡å‹æ£€æµ‹æ•ˆæœï¼ˆæ¯ç±»æµ‹è¯•5ä¸ªè§†é¢‘ï¼‰")
    print("=" * 60)
    
    # åŠ è½½æ¨¡å‹
    print("\nåŠ è½½YOLOæ¨¡å‹...")
    model = YOLO('runs/detect/train2/weights/best.pt')
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„è§†é¢‘
    test_videos = {
        'fire': 'datasets/fire_videos_organized/fire',
        'smoke': 'datasets/fire_videos_organized/smoke',
        'normal': 'datasets/fire_videos_organized/normal'
    }
    
    all_results = {}
    
    for category, video_dir in test_videos.items():
        video_dir = Path(video_dir)
        if not video_dir.exists():
            continue
        
        # è·å–æ‰€æœ‰è§†é¢‘
        videos = list(video_dir.glob('*.avi')) + list(video_dir.glob('*.mp4'))
        if not videos:
            continue
        
        # éšæœºé€‰æ‹©5ä¸ªè§†é¢‘æµ‹è¯•
        num_test_videos = min(5, len(videos))
        test_videos_list = random.sample(videos, num_test_videos)
        
        print(f"\n{'='*60}")
        print(f"æµ‹è¯• {category} ç±»åˆ« (ä» {len(videos)} ä¸ªè§†é¢‘ä¸­éšæœºé€‰æ‹© {num_test_videos} ä¸ª)")
        print(f"{'='*60}")
        
        category_results = []
        
        for idx, test_video in enumerate(test_videos_list, 1):
            print(f"\n[{idx}/{num_test_videos}] {test_video.name}")
            
            # è¯»å–è§†é¢‘
            cap = cv2.VideoCapture(str(test_video))
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            # éšæœºé‡‡æ ·50å¸§è¿›è¡Œæµ‹è¯•
            test_frame_count = min(50, total_frames)
            test_frames = sorted(random.sample(range(total_frames), test_frame_count))
            
            detections = []
            confidences = []
            
            for frame_idx in test_frames:
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                ret, frame = cap.read()
                if not ret:
                    break
                
                # YOLOæ£€æµ‹
                results = model(frame, verbose=False)
                
                if len(results[0].boxes) > 0:
                    detections.append(True)
                    # è·å–æœ€é«˜ç½®ä¿¡åº¦
                    max_conf = max([float(box.conf[0]) for box in results[0].boxes])
                    confidences.append(max_conf)
                else:
                    detections.append(False)
            
            cap.release()
            
            # ç»Ÿè®¡
            detection_rate = sum(detections) / len(detections) * 100 if detections else 0
            avg_conf = np.mean(confidences) if confidences else 0
            min_conf = min(confidences) if confidences else 0
            max_conf = max(confidences) if confidences else 0
            
            result = {
                'video': test_video.name,
                'total_frames': total_frames,
                'frames_tested': len(detections),
                'detection_rate': detection_rate,
                'avg_confidence': avg_conf,
                'min_confidence': min_conf,
                'max_confidence': max_conf,
                'detections_count': sum(detections)
            }
            category_results.append(result)
            
            print(f"  æ€»å¸§æ•°: {total_frames}, æµ‹è¯•: {len(detections)}å¸§, æ£€æµ‹: {sum(detections)}å¸§")
            print(f"  æ£€æµ‹ç‡: {detection_rate:.2f}%")
            print(f"  ç½®ä¿¡åº¦: å¹³å‡={avg_conf:.3f}, èŒƒå›´=[{min_conf:.3f}, {max_conf:.3f}]")
        
        # è®¡ç®—è¯¥ç±»åˆ«çš„å¹³å‡ç»Ÿè®¡
        avg_detection_rate = np.mean([r['detection_rate'] for r in category_results])
        avg_confidence = np.mean([r['avg_confidence'] for r in category_results if r['avg_confidence'] > 0])
        
        all_results[category] = {
            'videos_tested': num_test_videos,
            'individual_results': category_results,
            'avg_detection_rate': avg_detection_rate,
            'avg_confidence': avg_confidence
        }
        
        print(f"\n{category} ç±»åˆ«å¹³å‡:")
        print(f"  å¹³å‡æ£€æµ‹ç‡: {avg_detection_rate:.2f}%")
        print(f"  å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
    
    return all_results
    return results_summary


def test_feature_extraction():
    """æµ‹è¯•ç‰¹å¾æå–æ•ˆæœ"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•2: ç‰¹å¾æå–æ•ˆæœ")
    print("=" * 60)
    
    # åŠ è½½æ¨¡å‹å’Œç‰¹å¾æå–å™¨
    model = YOLO('runs/detect/train2/weights/best.pt')
    extractor = FeatureExtractor()
    
    # éšæœºé€‰æ‹©ä¸€ä¸ªç«ç¾è§†é¢‘
    fire_dir = Path('datasets/fire_videos_organized/fire')
    videos = list(fire_dir.glob('*.avi')) + list(fire_dir.glob('*.mp4'))
    
    if not videos:
        print("æœªæ‰¾åˆ°æµ‹è¯•è§†é¢‘")
        return
    
    test_video = random.choice(videos)
    print(f"\næµ‹è¯•è§†é¢‘: {test_video.name}")
    print(f"  (ä» {len(videos)} ä¸ªç«ç¾è§†é¢‘ä¸­éšæœºé€‰æ‹©)")
    
    # è¯»å–è§†é¢‘
    cap = cv2.VideoCapture(str(test_video))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # éšæœºé‡‡æ ·60å¸§è¿›è¡Œç‰¹å¾æå–æµ‹è¯•
    test_frame_count = min(60, total_frames)
    test_frames = sorted(random.sample(range(total_frames), test_frame_count))
    
    # æå–ç‰¹å¾
    features_list = []
    for frame_idx in test_frames:
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        if not ret:
            break
        
        # YOLOæ£€æµ‹
        results = model(frame, verbose=False)
        
        # æå–ç‰¹å¾
        features = extractor.get_best_detection(results, frame.shape)
        features_list.append(features)
    
    cap.release()
    
    # åˆ†æç‰¹å¾
    features_array = np.array(features_list)
    
    print(f"\næå–çš„ç‰¹å¾åºåˆ—:")
    print(f"  åºåˆ—é•¿åº¦: {len(features_list)}")
    print(f"  ç‰¹å¾ç»´åº¦: {features_array.shape}")
    print(f"\nç‰¹å¾ç»Ÿè®¡:")
    print(f"  ä¸­å¿ƒç‚¹x (cx): {features_array[:, 0].mean():.3f} Â± {features_array[:, 0].std():.3f}")
    print(f"  ä¸­å¿ƒç‚¹y (cy): {features_array[:, 1].mean():.3f} Â± {features_array[:, 1].std():.3f}")
    print(f"  å®½åº¦ (w): {features_array[:, 2].mean():.3f} Â± {features_array[:, 2].std():.3f}")
    print(f"  é«˜åº¦ (h): {features_array[:, 3].mean():.3f} Â± {features_array[:, 3].std():.3f}")
    print(f"  é¢ç§¯ (area): {features_array[:, 4].mean():.3f} Â± {features_array[:, 4].std():.3f}")
    print(f"  å®½é«˜æ¯” (ratio): {features_array[:, 5].mean():.3f} Â± {features_array[:, 5].std():.3f}")
    print(f"  ç½®ä¿¡åº¦ (conf): {features_array[:, 6].mean():.3f} Â± {features_array[:, 6].std():.3f}")
    print(f"  ç±»åˆ« (cls): {features_array[:, 7].mean():.3f}")
    
    # æ£€æŸ¥ç‰¹å¾æ˜¯å¦æœ‰æ•ˆ
    print(f"\nç‰¹å¾æœ‰æ•ˆæ€§æ£€æŸ¥:")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ£€æµ‹
    has_detection = (features_array[:, 6] > 0).sum()
    detection_rate = has_detection / len(features_list) * 100
    print(f"  æœ‰æ£€æµ‹çš„å¸§æ•°: {has_detection}/{len(features_list)}")
    print(f"  æ£€æµ‹ç‡: {detection_rate:.2f}%")
    
    # æ£€æŸ¥ç‰¹å¾å˜åŒ–
    feature_variance = features_array.var(axis=0)
    print(f"  ç‰¹å¾æ–¹å·®: {feature_variance}")
    
    if detection_rate >= 40:
        print(f"\nâœ… ç‰¹å¾æå–æ•ˆæœè‰¯å¥½ï¼")
        return True
    else:
        print(f"\nâš ï¸  æ£€æµ‹ç‡è¾ƒä½ï¼Œå¯èƒ½å½±å“è®­ç»ƒæ•ˆæœ")
        return False


def test_sequence_generation():
    """æµ‹è¯•åºåˆ—ç”Ÿæˆ"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•3: åºåˆ—ç”Ÿæˆæµ‹è¯•")
    print("=" * 60)
    
    # ç›´æ¥ä»3_prepare_lstm_dataå¯¼å…¥
    import importlib.util
    spec = importlib.util.spec_from_file_location("prepare_lstm_data", Path(__file__).parent / "3_prepare_lstm_data.py")
    prepare_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(prepare_module)
    LSTMDataPreparer = prepare_module.LSTMDataPreparer
    
    # åˆå§‹åŒ–
    preparer = LSTMDataPreparer(
        yolo_model_path='runs/detect/train2/weights/best.pt',
        sequence_length=30
    )
    
    # éšæœºé€‰æ‹©ä¸€ä¸ªè§†é¢‘
    fire_dir = Path('datasets/fire_videos_organized/fire')
    videos = list(fire_dir.glob('*.avi')) + list(fire_dir.glob('*.mp4'))
    
    if not videos:
        print("æœªæ‰¾åˆ°æµ‹è¯•è§†é¢‘")
        return
    
    test_video = random.choice(videos)
    print(f"\næµ‹è¯•è§†é¢‘: {test_video.name}")
    
    # æå–ç‰¹å¾
    print("æå–ç‰¹å¾...")
    features = preparer.extract_features_from_video(str(test_video), stride=5)
    
    print(f"\næå–ç»“æœ:")
    print(f"  ç‰¹å¾å‘é‡æ•°: {len(features)}")
    
    # åˆ›å»ºåºåˆ—
    if len(features) >= 30:
        sequences, labels = preparer.create_sequences(features, label=2)
        print(f"  ç”Ÿæˆåºåˆ—æ•°: {len(sequences)}")
        print(f"  åºåˆ—å½¢çŠ¶: {sequences.shape}")
        print(f"\nâœ… åºåˆ—ç”ŸæˆæˆåŠŸï¼")
        return True
    else:
        print(f"\nâš ï¸  ç‰¹å¾æ•°é‡ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆåºåˆ—")
        return False


def estimate_training_time():
    """ä¼°ç®—è®­ç»ƒæ—¶é—´"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•4: è®­ç»ƒæ—¶é—´ä¼°ç®—")
    print("=" * 60)
    
    import time
    # ç›´æ¥ä»3_prepare_lstm_dataå¯¼å…¥
    import importlib.util
    spec = importlib.util.spec_from_file_location("prepare_lstm_data", Path(__file__).parent / "3_prepare_lstm_data.py")
    prepare_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(prepare_module)
    LSTMDataPreparer = prepare_module.LSTMDataPreparer
    
    # åˆå§‹åŒ–
    preparer = LSTMDataPreparer(
        yolo_model_path='runs/detect/train2/weights/best.pt',
        sequence_length=30
    )
    
    # éšæœºé€‰æ‹©ä¸€ä¸ªè§†é¢‘æµ‹è¯•å¤„ç†æ—¶é—´
    fire_dir = Path('datasets/fire_videos_organized/fire')
    videos = list(fire_dir.glob('*.avi')) + list(fire_dir.glob('*.mp4'))
    
    if not videos:
        print("æœªæ‰¾åˆ°æµ‹è¯•è§†é¢‘")
        return
    
    test_video = random.choice(videos)
    
    # è·å–è§†é¢‘ä¿¡æ¯
    cap = cv2.VideoCapture(str(test_video))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    duration = total_frames / fps if fps > 0 else 0
    cap.release()
    
    print(f"\næµ‹è¯•è§†é¢‘: {test_video.name}")
    print(f"  æ€»å¸§æ•°: {total_frames}")
    print(f"  å¸§ç‡: {fps} fps")
    print(f"  æ—¶é•¿: {duration:.1f} ç§’")
    
    # æµ‹è¯•å¤„ç†æ—¶é—´
    print(f"\nå¼€å§‹è®¡æ—¶...")
    start_time = time.time()
    
    features = preparer.extract_features_from_video(str(test_video), stride=5)
    
    elapsed_time = time.time() - start_time
    
    print(f"\nå¤„ç†æ—¶é—´: {elapsed_time:.1f} ç§’")
    print(f"å¤„ç†é€Ÿåº¦: {total_frames/elapsed_time:.1f} å¸§/ç§’")
    
    # ä¼°ç®—æ€»æ—¶é—´
    total_videos = 240
    avg_video_time = elapsed_time
    estimated_total_time = avg_video_time * total_videos
    
    print(f"\nä¼°ç®—æ€»æ—¶é—´:")
    print(f"  å•ä¸ªè§†é¢‘: {avg_video_time:.1f} ç§’")
    print(f"  240ä¸ªè§†é¢‘: {estimated_total_time/60:.1f} åˆ†é’Ÿ ({estimated_total_time/3600:.1f} å°æ—¶)")
    
    return estimated_total_time


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "ğŸ”¥" * 30)
    print("EmberGuard AI - ç‰¹å¾æå–æµ‹è¯•")
    print("ğŸ”¥" * 30)
    
    print("\nè¿™ä¸ªæµ‹è¯•ä¼š:")
    print("1. æµ‹è¯•YOLOæ¨¡å‹åœ¨ä¸åŒç±»åˆ«è§†é¢‘ä¸Šçš„æ£€æµ‹æ•ˆæœ")
    print("2. æµ‹è¯•ç‰¹å¾æå–å™¨çš„æ•ˆæœ")
    print("3. æµ‹è¯•åºåˆ—ç”Ÿæˆ")
    print("4. ä¼°ç®—å®Œæ•´è®­ç»ƒæ‰€éœ€æ—¶é—´")
    
    input("\næŒ‰Enteré”®å¼€å§‹æµ‹è¯•...")
    
    # æµ‹è¯•1: YOLOæ£€æµ‹
    try:
        yolo_results = test_yolo_detection()
    except Exception as e:
        print(f"\nâŒ YOLOæµ‹è¯•å¤±è´¥: {e}")
        return
    
    # æµ‹è¯•2: ç‰¹å¾æå–
    try:
        feature_ok = test_feature_extraction()
    except Exception as e:
        print(f"\nâŒ ç‰¹å¾æå–æµ‹è¯•å¤±è´¥: {e}")
        return
    
    # æµ‹è¯•3: åºåˆ—ç”Ÿæˆ
    try:
        sequence_ok = test_sequence_generation()
    except Exception as e:
        print(f"\nâŒ åºåˆ—ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        return
    
    # æµ‹è¯•4: æ—¶é—´ä¼°ç®—
    try:
        estimated_time = estimate_training_time()
    except Exception as e:
        print(f"\nâŒ æ—¶é—´ä¼°ç®—å¤±è´¥: {e}")
        estimated_time = None
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    print("\nYOLOæ£€æµ‹æ•ˆæœï¼ˆæ¯ç±»æµ‹è¯•5ä¸ªè§†é¢‘çš„å¹³å‡å€¼ï¼‰:")
    for category, result in yolo_results.items():
        print(f"  {category}:")
        print(f"    å¹³å‡æ£€æµ‹ç‡: {result['avg_detection_rate']:.2f}%")
        print(f"    å¹³å‡ç½®ä¿¡åº¦: {result['avg_confidence']:.3f}")
        print(f"    æµ‹è¯•è§†é¢‘æ•°: {result['videos_tested']}")
    
    # è¯„ä¼°æ¨¡å‹è´¨é‡
    print("\næ¨¡å‹è´¨é‡è¯„ä¼°:")
    fire_rate = yolo_results.get('fire', {}).get('avg_detection_rate', 0)
    smoke_rate = yolo_results.get('smoke', {}).get('avg_detection_rate', 0)
    normal_rate = yolo_results.get('normal', {}).get('avg_detection_rate', 0)
    
    issues = []
    if fire_rate < 70:
        issues.append(f"âš ï¸  ç«ç¾æ£€æµ‹ç‡åä½ ({fire_rate:.1f}%)")
    if smoke_rate < 70:
        issues.append(f"âš ï¸  çƒŸé›¾æ£€æµ‹ç‡åä½ ({smoke_rate:.1f}%)")
    if normal_rate > 20:
        issues.append(f"âš ï¸  æ­£å¸¸è§†é¢‘è¯¯æŠ¥ç‡åé«˜ ({normal_rate:.1f}%)")
    
    if issues:
        for issue in issues:
            print(f"  {issue}")
    else:
        print("  âœ… æ¨¡å‹æ€§èƒ½è‰¯å¥½")
    
    if feature_ok and sequence_ok:
        print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("\nå»ºè®®:")
        print("  - YOLOæ¨¡å‹å·¥ä½œæ­£å¸¸")
        print("  - ç‰¹å¾æå–æœ‰æ•ˆ")
        if normal_rate > 20:
            print("  - æ³¨æ„ï¼šæ­£å¸¸è§†é¢‘æœ‰ä¸€å®šè¯¯æŠ¥ï¼ŒLSTMéœ€è¦å­¦ä¹ åŒºåˆ†")
        print("  - å¯ä»¥å¼€å§‹å®Œæ•´è®­ç»ƒ")
        
        if estimated_time:
            print(f"\né¢„è®¡æ•°æ®å‡†å¤‡æ—¶é—´: {estimated_time/3600:.1f} å°æ—¶")
        
        print("\nä¸‹ä¸€æ­¥:")
        print("  python scripts/3_prepare_lstm_data.py")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡")
        print("å»ºè®®æ£€æŸ¥YOLOæ¨¡å‹å’Œæ•°æ®è´¨é‡")


if __name__ == "__main__":
    main()
