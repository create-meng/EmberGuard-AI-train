"""
YOLO+LSTMç«ç¾æ£€æµ‹è„šæœ¬
æ”¯æŒå›¾ç‰‡ã€è§†é¢‘ã€æ‘„åƒå¤´æ£€æµ‹
"""
import sys
from pathlib import Path
import cv2
import numpy as np
import argparse
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from emberguard.pipeline import FireDetectionPipeline


def detect_image(pipeline, image_path, output_path=None, show=True):
    """
    æ£€æµ‹å•å¼ å›¾ç‰‡
    
    Args:
        pipeline: æ£€æµ‹ç®¡é“
        image_path: å›¾ç‰‡è·¯å¾„
        output_path: è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰
        show: æ˜¯å¦æ˜¾ç¤ºç»“æœ
    """
    print(f"\n{'='*60}")
    print(f"æ£€æµ‹å›¾ç‰‡: {image_path}")
    print(f"{'='*60}")
    
    # è¯»å–å›¾ç‰‡
    img = cv2.imread(image_path)
    if img is None:
        print(f"âŒ æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
        return
    
    # é‡ç½®ç¼“å†²åŒº
    pipeline.reset_buffer()
    
    # æ£€æµ‹ï¼ˆé‡å¤30æ¬¡å¡«å……ç¼“å†²åŒºï¼‰
    for _ in range(30):
        result = pipeline.detect_frame(img)
    
    # æ‰“å°ç»“æœ
    print(f"\nğŸ”¥ æ£€æµ‹ç»“æœ:")
    print(f"{'='*60}")
    
    # YOLOæ£€æµ‹
    if result['yolo_detections']:
        print(f"\nğŸ“¹ YOLOæ£€æµ‹:")
        for det in result['yolo_detections']:
            print(f"  - {det['class_name']}: ç½®ä¿¡åº¦ {det['confidence']:.3f}")
    else:
        print(f"\nğŸ“¹ YOLOæ£€æµ‹: æœªæ£€æµ‹åˆ°ç«/çƒŸ")
    
    # LSTMé¢„æµ‹
    if 'lstm_prediction' in result:
        print(f"\nğŸ§  LSTMé¢„æµ‹:")
        print(f"  - ç±»åˆ«: {result['lstm_class_name']}")
        print(f"  - ç½®ä¿¡åº¦: {result['lstm_confidence']:.3f}")
        print(f"  - æ¦‚ç‡åˆ†å¸ƒ:")
        for name, prob in result['lstm_probabilities'].items():
            print(f"    {name}: {prob:.3f}")
    else:
        print(f"\nğŸ§  LSTMé¢„æµ‹: ç¼“å†²åŒºæœªæ»¡ï¼ˆéœ€è¦30å¸§ï¼‰")
    
    # ç»˜åˆ¶ç»“æœ
    img_vis = pipeline._draw_results(img, result)
    
    # ä¿å­˜ç»“æœ
    if output_path:
        cv2.imwrite(output_path, img_vis)
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜: {output_path}")
    
    # æ˜¾ç¤ºç»“æœ
    if show:
        cv2.imshow('EmberGuard AI - Detection Result', img_vis)
        print(f"\næŒ‰ä»»æ„é”®ç»§ç»­...")
        cv2.waitKey(0)
        cv2.destroyAllWindows()


def detect_video(pipeline, video_path, output_path=None, show=True):
    """
    æ£€æµ‹è§†é¢‘
    
    Args:
        pipeline: æ£€æµ‹ç®¡é“
        video_path: è§†é¢‘è·¯å¾„
        output_path: è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰
        show: æ˜¯å¦æ˜¾ç¤ºç»“æœ
    """
    print(f"\n{'='*60}")
    print(f"æ£€æµ‹è§†é¢‘: {video_path}")
    print(f"{'='*60}")
    
    # æ‰“å¼€è§†é¢‘
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
        return
    
    # è§†é¢‘ä¿¡æ¯
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"\nğŸ“¹ è§†é¢‘ä¿¡æ¯:")
    print(f"  - åˆ†è¾¨ç‡: {width}x{height}")
    print(f"  - å¸§ç‡: {fps} fps")
    print(f"  - æ€»å¸§æ•°: {total_frames}")
    print(f"  - æ—¶é•¿: {total_frames/fps:.1f} ç§’")
    
    # è¾“å‡ºè§†é¢‘
    writer = None
    if output_path:
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    # é‡ç½®ç¼“å†²åŒº
    pipeline.reset_buffer()
    
    # ç»Ÿè®¡
    frame_count = 0
    lstm_predictions = {0: 0, 1: 0, 2: 0}  # æ— ç«ã€çƒŸé›¾ã€ç«ç„°
    
    print(f"\nğŸš€ å¼€å§‹æ£€æµ‹...")
    print(f"{'='*60}")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # æ£€æµ‹
        result = pipeline.detect_frame(frame)
        
        # ç»Ÿè®¡LSTMé¢„æµ‹
        if 'lstm_prediction' in result:
            pred = result['lstm_prediction']
            lstm_predictions[pred] += 1
        
        # ç»˜åˆ¶ç»“æœ
        frame_vis = pipeline._draw_results(frame, result)
        
        # ä¿å­˜
        if writer:
            writer.write(frame_vis)
        
        # æ˜¾ç¤º
        if show:
            cv2.imshow('EmberGuard AI - Video Detection', frame_vis)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                print(f"\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ£€æµ‹")
                break
        
        frame_count += 1
        
        # æ˜¾ç¤ºè¿›åº¦
        if frame_count % 30 == 0:
            progress = 100 * frame_count / total_frames
            print(f"  è¿›åº¦: {frame_count}/{total_frames} ({progress:.1f}%)", end='\r')
    
    # é‡Šæ”¾èµ„æº
    cap.release()
    if writer:
        writer.release()
    cv2.destroyAllWindows()
    
    # è¾“å‡ºç»Ÿè®¡
    print(f"\n\n{'='*60}")
    print(f"ğŸ”¥ æ£€æµ‹å®Œæˆ")
    print(f"{'='*60}")
    print(f"\nğŸ“Š ç»Ÿè®¡ç»“æœ:")
    print(f"  - å¤„ç†å¸§æ•°: {frame_count}")
    
    if lstm_predictions[0] + lstm_predictions[1] + lstm_predictions[2] > 0:
        total_pred = sum(lstm_predictions.values())
        print(f"\nğŸ§  LSTMé¢„æµ‹åˆ†å¸ƒ:")
        print(f"  - æ— ç«: {lstm_predictions[0]} ({100*lstm_predictions[0]/total_pred:.1f}%)")
        print(f"  - çƒŸé›¾: {lstm_predictions[1]} ({100*lstm_predictions[1]/total_pred:.1f}%)")
        print(f"  - ç«ç„°: {lstm_predictions[2]} ({100*lstm_predictions[2]/total_pred:.1f}%)")
        
        # æœ€ç»ˆåˆ¤æ–­
        final_pred = max(lstm_predictions, key=lstm_predictions.get)
        class_names = {0: "æ— ç«", 1: "çƒŸé›¾", 2: "ç«ç„°"}
        print(f"\nâœ… æœ€ç»ˆåˆ¤æ–­: {class_names[final_pred]} (å‡ºç° {lstm_predictions[final_pred]} æ¬¡)")
    
    if output_path:
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜: {output_path}")


def detect_camera(pipeline, camera_id=0):
    """
    æ£€æµ‹æ‘„åƒå¤´
    
    Args:
        pipeline: æ£€æµ‹ç®¡é“
        camera_id: æ‘„åƒå¤´ID
    """
    print(f"\n{'='*60}")
    print(f"æ£€æµ‹æ‘„åƒå¤´: {camera_id}")
    print(f"{'='*60}")
    
    # æ‰“å¼€æ‘„åƒå¤´
    cap = cv2.VideoCapture(camera_id)
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´: {camera_id}")
        return
    
    # æ‘„åƒå¤´ä¿¡æ¯
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    
    print(f"\nğŸ“¹ æ‘„åƒå¤´ä¿¡æ¯:")
    print(f"  - åˆ†è¾¨ç‡: {width}x{height}")
    print(f"  - å¸§ç‡: {fps} fps")
    
    # é‡ç½®ç¼“å†²åŒº
    pipeline.reset_buffer()
    
    print(f"\nğŸš€ å¼€å§‹å®æ—¶æ£€æµ‹...")
    print(f"{'='*60}")
    print(f"æŒ‰ 'q' é€€å‡ºï¼ŒæŒ‰ 's' æˆªå›¾ä¿å­˜")
    
    frame_count = 0
    
    while True:
        ret, frame = cap.read()
        if not ret:
            print(f"\nâŒ æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
            break
        
        # æ£€æµ‹
        result = pipeline.detect_frame(frame)
        
        # ç»˜åˆ¶ç»“æœ
        frame_vis = pipeline._draw_results(frame, result)
        
        # æ·»åŠ å¸§æ•°ä¿¡æ¯
        cv2.putText(frame_vis, f"Frame: {frame_count}", (10, height-10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # æ˜¾ç¤º
        cv2.imshow('EmberGuard AI - Camera Detection (Press Q to quit, S to save)', frame_vis)
        
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            print(f"\nâš ï¸  ç”¨æˆ·é€€å‡º")
            break
        elif key == ord('s'):
            # ä¿å­˜æˆªå›¾
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            save_path = f"detection_saves/camera_{timestamp}.jpg"
            Path("detection_saves").mkdir(exist_ok=True)
            cv2.imwrite(save_path, frame_vis)
            print(f"\nğŸ’¾ æˆªå›¾å·²ä¿å­˜: {save_path}")
        
        frame_count += 1
    
    # é‡Šæ”¾èµ„æº
    cap.release()
    cv2.destroyAllWindows()
    
    print(f"\n{'='*60}")
    print(f"ğŸ”¥ æ£€æµ‹ç»“æŸ")
    print(f"{'='*60}")
    print(f"æ€»å¸§æ•°: {frame_count}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='EmberGuard AI - YOLO+LSTMç«ç¾æ£€æµ‹')
    parser.add_argument('--source', type=str, required=True,
                       help='è¾“å…¥æºï¼šå›¾ç‰‡è·¯å¾„ã€è§†é¢‘è·¯å¾„ã€æ‘„åƒå¤´IDï¼ˆ0,1,2...ï¼‰')
    parser.add_argument('--yolo', type=str, default='runs/detect/train2/weights/best.pt',
                       help='YOLOæ¨¡å‹è·¯å¾„')
    parser.add_argument('--lstm', type=str, default='models/lstm/train/best.pt',
                       help='LSTMæ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼Œä¸æŒ‡å®šåˆ™åªç”¨YOLOï¼‰')
    parser.add_argument('--output', type=str, default=None,
                       help='è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--no-show', action='store_true',
                       help='ä¸æ˜¾ç¤ºç»“æœçª—å£')
    parser.add_argument('--conf', type=float, default=0.25,
                       help='YOLOç½®ä¿¡åº¦é˜ˆå€¼')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸ”¥ EmberGuard AI - ç«ç¾æ£€æµ‹ç³»ç»Ÿ")
    print("=" * 60)
    print(f"\nğŸ“‹ é…ç½®:")
    print(f"  - YOLOæ¨¡å‹: {args.yolo}")
    print(f"  - LSTMæ¨¡å‹: {args.lstm if args.lstm else 'æœªä½¿ç”¨'}")
    print(f"  - è¾“å…¥æº: {args.source}")
    print(f"  - ç½®ä¿¡åº¦é˜ˆå€¼: {args.conf}")
    
    # æ£€æŸ¥LSTMæ¨¡å‹
    lstm_path = args.lstm if args.lstm and Path(args.lstm).exists() else None
    if args.lstm and not lstm_path:
        print(f"\nâš ï¸  LSTMæ¨¡å‹ä¸å­˜åœ¨: {args.lstm}")
        print(f"å°†åªä½¿ç”¨YOLOæ£€æµ‹")
    
    # åˆ›å»ºæ£€æµ‹ç®¡é“
    print(f"\nğŸ”§ åˆå§‹åŒ–æ£€æµ‹ç®¡é“...")
    pipeline = FireDetectionPipeline(
        yolo_model_path=args.yolo,
        lstm_model_path=lstm_path,
        sequence_length=30
    )
    
    # åˆ¤æ–­è¾“å…¥ç±»å‹
    source = args.source
    
    # æ‘„åƒå¤´
    if source.isdigit():
        detect_camera(pipeline, int(source))
    
    # å›¾ç‰‡
    elif source.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.webp')):
        if not Path(source).exists():
            print(f"\nâŒ å›¾ç‰‡ä¸å­˜åœ¨: {source}")
            return
        detect_image(pipeline, source, args.output, not args.no_show)
    
    # è§†é¢‘
    elif source.lower().endswith(('.mp4', '.avi', '.mov', '.mkv', '.flv')):
        if not Path(source).exists():
            print(f"\nâŒ è§†é¢‘ä¸å­˜åœ¨: {source}")
            return
        detect_video(pipeline, source, args.output, not args.no_show)
    
    else:
        print(f"\nâŒ ä¸æ”¯æŒçš„è¾“å…¥æ ¼å¼: {source}")
        print(f"æ”¯æŒçš„æ ¼å¼:")
        print(f"  - å›¾ç‰‡: .jpg, .jpeg, .png, .bmp, .webp")
        print(f"  - è§†é¢‘: .mp4, .avi, .mov, .mkv, .flv")
        print(f"  - æ‘„åƒå¤´: 0, 1, 2...")


if __name__ == "__main__":
    main()
