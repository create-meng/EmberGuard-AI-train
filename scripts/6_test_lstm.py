"""
æµ‹è¯•LSTMæ¨¡å‹
å¿«é€Ÿæµ‹è¯•è®­ç»ƒå¥½çš„LSTMæ¨¡å‹åœ¨æµ‹è¯•è§†é¢‘ä¸Šçš„è¡¨ç°
"""
import sys
from pathlib import Path
import cv2
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from emberguard.pipeline import FireDetectionPipeline


def test_on_video(video_path, model_path, yolo_path='runs/detect/train2/weights/best.pt'):
    """
    åœ¨å•ä¸ªè§†é¢‘ä¸Šæµ‹è¯•
    
    Args:
        video_path: æµ‹è¯•è§†é¢‘è·¯å¾„
        model_path: LSTMæ¨¡å‹è·¯å¾„
        yolo_path: YOLOæ¨¡å‹è·¯å¾„
    """
    print(f"\n{'='*60}")
    print(f"æµ‹è¯•è§†é¢‘: {video_path}")
    print(f"{'='*60}")
    
    # åˆ›å»ºæ£€æµ‹ç®¡é“
    pipeline = FireDetectionPipeline(
        yolo_model_path=yolo_path,
        lstm_model_path=model_path,
        sequence_length=30
    )
    
    # æ‰“å¼€è§†é¢‘
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
        return
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    
    print(f"è§†é¢‘ä¿¡æ¯: {total_frames} å¸§, {fps} fps")
    print(f"\nå¼€å§‹æ£€æµ‹...")
    
    # ç»Ÿè®¡
    frame_count = 0
    yolo_detections = 0
    lstm_predictions = {0: 0, 1: 0, 2: 0}  # æ— ç«ã€çƒŸé›¾ã€ç«ç„°
    lstm_confidences = []
    
    # é‡ç½®ç¼“å†²åŒº
    pipeline.reset_buffer()
    
    # å¤„ç†è§†é¢‘
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # æ£€æµ‹
        result = pipeline.detect_frame(frame)
        
        # ç»Ÿè®¡YOLOæ£€æµ‹
        if result['has_detection']:
            yolo_detections += 1
        
        # ç»Ÿè®¡LSTMé¢„æµ‹ï¼ˆç¼“å†²åŒºæ»¡åï¼‰
        if 'lstm_prediction' in result:
            pred = result['lstm_prediction']
            lstm_predictions[pred] += 1
            lstm_confidences.append(result['lstm_confidence'])
        
        frame_count += 1
        
        # æ¯30å¸§æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
        if frame_count % 30 == 0:
            print(f"  å¤„ç†è¿›åº¦: {frame_count}/{total_frames} ({100*frame_count/total_frames:.1f}%)", end='\r')
    
    cap.release()
    
    # è¾“å‡ºç»“æœ
    print(f"\n\n{'='*60}")
    print("æ£€æµ‹ç»“æœ")
    print(f"{'='*60}")
    
    print(f"\nYOLOæ£€æµ‹:")
    print(f"  æ£€æµ‹åˆ°ç«/çƒŸçš„å¸§æ•°: {yolo_detections}/{frame_count} ({100*yolo_detections/frame_count:.1f}%)")
    
    if lstm_confidences:
        print(f"\nLSTMé¢„æµ‹ (ç¼“å†²åŒºæ»¡å):")
        total_lstm = sum(lstm_predictions.values())
        print(f"  æ€»é¢„æµ‹æ¬¡æ•°: {total_lstm}")
        print(f"  æ— ç« (0): {lstm_predictions[0]} ({100*lstm_predictions[0]/total_lstm:.1f}%)")
        print(f"  çƒŸé›¾ (1): {lstm_predictions[1]} ({100*lstm_predictions[1]/total_lstm:.1f}%)")
        print(f"  ç«ç„° (2): {lstm_predictions[2]} ({100*lstm_predictions[2]/total_lstm:.1f}%)")
        print(f"  å¹³å‡ç½®ä¿¡åº¦: {np.mean(lstm_confidences):.3f}")
        
        # å®æ—¶ç«ç¾æ£€æµ‹åˆ¤æ–­é€»è¾‘ï¼šä¸€æ—¦æ£€æµ‹åˆ°ç«ç„°/çƒŸé›¾å°±æŠ¥è­¦
        has_fire = lstm_predictions[2] > 0
        has_smoke = lstm_predictions[1] > 0
        
        print(f"\nâš ï¸  å®æ—¶ç«ç¾æ£€æµ‹åˆ¤æ–­:")
        if has_fire:
            fire_ratio = 100 * lstm_predictions[2] / total_lstm
            print(f"  ğŸ”¥ æ£€æµ‹åˆ°ç«ç„°ï¼({lstm_predictions[2]}æ¬¡, {fire_ratio:.1f}%)")
            print(f"  âš ï¸  å»ºè®®ï¼šç«‹å³æŠ¥è­¦ï¼")
        if has_smoke:
            smoke_ratio = 100 * lstm_predictions[1] / total_lstm
            print(f"  ğŸ’¨ æ£€æµ‹åˆ°çƒŸé›¾ï¼({lstm_predictions[1]}æ¬¡, {smoke_ratio:.1f}%)")
            if not has_fire:
                print(f"  âš ï¸  å»ºè®®ï¼šå‘å‡ºé¢„è­¦ï¼Œå¯†åˆ‡ç›‘æ§ï¼")
        
        if not has_fire and not has_smoke:
            print(f"  âœ“ æœªæ£€æµ‹åˆ°ç«ç¾è¿¹è±¡")
            
    else:
        print(f"\nâš ï¸  è§†é¢‘å¤ªçŸ­ï¼ŒLSTMç¼“å†²åŒºæœªæ»¡ï¼ˆéœ€è¦è‡³å°‘30å¸§ï¼‰")


def test_on_mixed_videos():
    """æµ‹è¯•mixedç›®å½•ä¸­çš„4ä¸ªæµ‹è¯•è§†é¢‘"""
    mixed_dir = Path("datasets/fire_videos_organized/mixed")
    
    if not mixed_dir.exists():
        print(f"âŒ æµ‹è¯•ç›®å½•ä¸å­˜åœ¨: {mixed_dir}")
        return
    
    # è·å–æ‰€æœ‰è§†é¢‘
    videos = list(mixed_dir.glob("*.avi")) + list(mixed_dir.glob("*.mp4"))
    
    if not videos:
        print(f"âŒ æœªæ‰¾åˆ°æµ‹è¯•è§†é¢‘")
        return
    
    print(f"\nğŸ”¥ğŸ”¥ğŸ”¥ EmberGuard AI - LSTMæ¨¡å‹æµ‹è¯• ğŸ”¥ğŸ”¥ğŸ”¥")
    print(f"\næ‰¾åˆ° {len(videos)} ä¸ªæµ‹è¯•è§†é¢‘")
    
    # æµ‹è¯•æ¯ä¸ªè§†é¢‘
    model_path = "models/lstm/best.pt"
    
    if not Path(model_path).exists():
        print(f"\nâŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("è¯·å…ˆè®­ç»ƒæ¨¡å‹")
        return
    
    for i, video in enumerate(videos, 1):
        print(f"\n\n{'#'*60}")
        print(f"æµ‹è¯• {i}/{len(videos)}")
        print(f"{'#'*60}")
        
        test_on_video(str(video), model_path)
        
        input("\næŒ‰Enteré”®ç»§ç»­ä¸‹ä¸€ä¸ªè§†é¢‘...")


def test_single_video(video_path):
    """æµ‹è¯•å•ä¸ªè§†é¢‘"""
    model_path = "models/lstm/best.pt"
    
    if not Path(model_path).exists():
        print(f"\nâŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("è¯·å…ˆè®­ç»ƒæ¨¡å‹")
        return
    
    if not Path(video_path).exists():
        print(f"\nâŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return
    
    print(f"\nğŸ”¥ğŸ”¥ğŸ”¥ EmberGuard AI - LSTMæ¨¡å‹æµ‹è¯• ğŸ”¥ğŸ”¥ğŸ”¥")
    test_on_video(video_path, model_path)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æµ‹è¯•LSTMæ¨¡å‹')
    parser.add_argument('--video', type=str, default=None,
                       help='æµ‹è¯•å•ä¸ªè§†é¢‘çš„è·¯å¾„')
    parser.add_argument('--model', type=str, default='models/lstm/best.pt',
                       help='LSTMæ¨¡å‹è·¯å¾„')
    
    args = parser.parse_args()
    
    if args.video:
        # æµ‹è¯•å•ä¸ªè§†é¢‘
        test_single_video(args.video)
    else:
        # æµ‹è¯•mixedç›®å½•ä¸­çš„æ‰€æœ‰è§†é¢‘
        test_on_mixed_videos()


if __name__ == "__main__":
    main()
