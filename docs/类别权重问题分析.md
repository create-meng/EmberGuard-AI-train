# 类别权重问题分析

## 📊 当前状态

### 数据分布
```
Normal (无火):  599,533 样本 (47.6%)  → 权重 0.70
Smoke (烟雾):   573,681 样本 (45.5%)  → 权重 0.73
Fire (火焰):     86,466 样本 (6.9%)   → 权重 4.83 ⚠️
```

### 权重计算公式
```python
class_weight = total_samples / (num_classes * class_samples)

Fire权重 = 1,259,680 / (3 × 86,466) = 4.85
```

---

## ⚠️ 潜在问题

### 问题1：Fire权重过高（4.83x）

**影响**：
1. **Loss放大**：Fire样本的loss被放大4.83倍
2. **梯度过大**：反向传播时Fire的梯度是其他类别的5倍
3. **过度敏感**：模型可能过度关注Fire特征

**可能导致**：
- ✅ 优点：Fire召回率高（不会漏检火灾）
- ⚠️ 缺点1：将Smoke误判为Fire（假阳性）
- ⚠️ 缺点2：训练不稳定（loss震荡）
- ⚠️ 缺点3：Fire过拟合（训练acc高但验证acc低）

### 问题2：Smoke权重偏低（0.73x）

**影响**：
1. **被忽视**：Smoke的loss被降低到0.73倍
2. **学习不足**：模型可能不够重视Smoke特征

**可能导致**：
- ⚠️ Smoke召回率低（漏检烟雾）
- ⚠️ 将Smoke误判为Normal（假阴性）

### 问题3：类别间竞争失衡

**当前情况**：
```
Fire loss权重:   4.83x  (最高优先级)
Smoke loss权重:  0.73x  (被压制)
Normal loss权重: 0.70x  (被压制)
```

**问题**：
- Fire和Smoke/Normal的权重差距达到 **6.6倍**
- 模型会优先学习Fire特征，忽视Smoke和Normal的细微差异

---

## 📈 训练过程中的观察指标

### 1. 各类别准确率
```python
# 理想情况
Fire准确率:   > 95%  (高召回率)
Smoke准确率:  > 85%  (不被忽视)
Normal准确率: > 90%  (不被误判)

# 问题信号
Fire准确率:   > 98%  但 Smoke < 70%  → Fire权重过高
Smoke准确率:  < 70%  → 被忽视
Normal准确率: < 80%  → 被误判为Fire
```

### 2. 混淆矩阵
```
关注点：
- Fire → Smoke 误判率（应该低）
- Smoke → Fire 误判率（可能高 ⚠️）
- Normal → Fire 误判率（可能高 ⚠️）
```

### 3. Loss曲线
```
正常：平滑下降
异常：震荡、不收敛 → 权重过高
```

---

## 💡 解决方案

### 方案1：降低Fire权重（推荐）

**调整权重**：
```python
# 当前
Fire: 4.83x

# 建议
Fire: 2.5x  (降低一半)
或
Fire: 3.0x  (适中)
```

**优点**：
- ✅ 训练更稳定
- ✅ Smoke不会被忽视
- ✅ 减少误判

**缺点**：
- ⚠️ Fire召回率可能略降（但仍可接受）

**实施**：
```python
# 在 scripts/4_train_lstm.py 中
# 手动设置权重
class_weights = torch.FloatTensor([0.70, 0.73, 2.5]).to(device)
```

### 方案2：使用Focal Loss

**原理**：
- 自动降低易分类样本的权重
- 自动提高难分类样本的权重
- 不需要手动设置类别权重

**优点**：
- ✅ 自适应调整
- ✅ 更关注难样本
- ✅ 训练更稳定

**实施**：
```python
class FocalLoss(nn.Module):
    def __init__(self, alpha=0.25, gamma=2):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
    
    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss
        return focal_loss.mean()
```

### 方案3：数据增强（治本）

**方法**：
- 对Fire样本进行过采样
- 或对Normal/Smoke进行欠采样
- 使目标分布更均衡

**优点**：
- ✅ 从根本解决数据不平衡
- ✅ 不需要调整权重

**缺点**：
- ⚠️ 需要重新生成训练数据
- ⚠️ 可能导致过拟合

### 方案4：先观察再调整（当前策略）

**步骤**：
1. 先用当前权重训练10-20个epoch
2. 观察各类别准确率和混淆矩阵
3. 如果出现问题，再调整权重
4. 从checkpoint继续训练

**优点**：
- ✅ 不浪费已训练的模型
- ✅ 基于实际数据做决策

---

## 🎯 监控清单

### 每5个epoch检查：

1. **各类别准确率**
   ```
   Fire:   > 90%  ✅
   Smoke:  > 80%  ✅
   Normal: > 85%  ✅
   ```

2. **混淆矩阵**
   ```
   Smoke → Fire 误判率 < 15%  ✅
   Normal → Fire 误判率 < 10%  ✅
   ```

3. **Loss曲线**
   ```
   平滑下降  ✅
   无震荡    ✅
   ```

4. **Fire类别过拟合检查**
   ```
   训练acc - 验证acc < 5%  ✅
   ```

### 问题信号：

- ⚠️ Smoke准确率 < 70%
- ⚠️ Smoke → Fire 误判率 > 20%
- ⚠️ Loss震荡不收敛
- ⚠️ Fire训练acc > 95% 但验证acc < 85%

**出现问题时**：
1. 停止训练
2. 调整Fire权重到2.5x
3. 从checkpoint继续训练

---

## 📝 实施建议

### 当前（Epoch 1-20）
```bash
# 使用当前权重继续训练
python scripts/4_train_lstm.py --epochs 20 --resume

# 每5个epoch检查一次
python scripts/6_test_lstm.py
```

### 如果出现问题（Epoch 20+）
```python
# 修改 scripts/4_train_lstm.py
# 找到这一行：
class_weights = total_samples / (len(label_counts) * label_counts)

# 改为：
class_weights = torch.FloatTensor([0.70, 0.73, 2.5]).to(device)
print("使用调整后的类别权重: Fire=2.5x")
```

```bash
# 从checkpoint继续训练
python scripts/4_train_lstm.py --epochs 50 --resume
```

---

## 🔬 实验对比（建议）

如果时间允许，可以做对比实验：

### 实验A：当前权重（Fire 4.83x）
- 训练20个epoch
- 记录各类别准确率

### 实验B：降低权重（Fire 2.5x）
- 从头训练20个epoch
- 对比准确率差异

### 实验C：Focal Loss
- 不使用类别权重
- 使用Focal Loss
- 对比效果

**预期结果**：
- 实验A：Fire召回率最高，但可能误判多
- 实验B：更均衡，Smoke准确率更高
- 实验C：最稳定，但实施复杂

---

## 💭 我的建议

1. **现在**：先用当前权重训练20个epoch
2. **观察**：每5个epoch检查各类别准确率
3. **调整**：如果Smoke < 70%，降低Fire权重到2.5x
4. **继续**：从checkpoint继续训练到50个epoch

**原因**：
- 已经训练了1个epoch，不要浪费
- 实际数据比理论分析更可靠
- 可以随时调整并继续训练

**最坏情况**：
- 如果20个epoch后效果很差
- 重新训练也只需要10小时
- 总时间成本可接受
