================================================================================
                    EmberGuard AI - YOLO+LSTM架构详解
================================================================================


================================================================================
目录
================================================================================

1. 架构概述
2. 核心概念
3. 类别映射
4. 8维特征向量
5. LSTM模型架构
6. 完整训练流程
   6.1 步骤1：训练YOLO
   6.2 步骤2：用YOLO提取特征
   6.3 步骤3：制作LSTM训练样本
   6.4 步骤4：训练LSTM
7. 推理阶段
8. 关键问题解答
9. 数据流动
10. 完整工具链
11. 高级特性
12. 核心代码位置
13. 技术创新点
14. 总结


================================================================================
1. 架构概述
================================================================================

YOLO+LSTM = 空间检测器 + 时序分析器

┌─────────────────────────────────────────────────────────┐
│  YOLO（空间检测器）                                      │
│  - 输入：单帧图像 (H×W×3)                                │
│  - 输出：边界框 + 类别(0=smoke, 1=fire) + 置信度         │
│  - 作用：检测"哪里有火/烟"                               │
│  - 特点：快速，无记忆                                    │
└─────────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────────┐
│  特征提取器（FeatureExtractor）                          │
│  - 输入：YOLO检测结果                                    │
│  - 输出：8维特征向量                                     │
│  - 特征：[cx, cy, w, h, area, ratio, conf, cls]         │
└─────────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────────┐
│  滑动窗口缓冲区（deque）                                 │
│  - 容量：30帧                                            │
│  - 机制：1-30, 2-31, 3-32...（每帧移动1帧）             │
│  - 实现：deque(maxlen=30)                                │
└─────────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────────┐
│  LSTM（时序分析器）                                      │
│  - 输入：30帧特征序列 (30×8)                             │
│  - 输出：3类概率 [无火, 烟雾, 火焰]                      │
│  - 作用：判断"是否真火灾"                                │
│  - 特点：有记忆，分析趋势                                │
└─────────────────────────────────────────────────────────┘


================================================================================
2. 核心概念
================================================================================

YOLO+LSTM 是一个"眼睛+大脑"的组合架构：

【YOLO = "眼睛"（空间检测器）】
- 作用：看每一帧画面，识别"哪里有火/烟"
- 输入：单张图片 (640x640)
- 输出：边界框 + 类别 + 置信度
- 特点：快速，但没有记忆

【LSTM = "大脑"（时序分析器）】
- 作用：分析30帧的变化趋势，判断"是不是真火灾"
- 输入：30帧特征序列 (30×8矩阵)
- 输出：3个概率 [无火, 烟雾, 火焰]
- 特点：有记忆，能看到变化趋势

【协作方式】
1. YOLO先看每一帧，记录检测结果
2. 特征提取器把检测结果转换成8个数字
3. 缓冲区收集最近30帧的数字
4. LSTM分析这30帧的趋势，做出最终判断


================================================================================
3. 类别映射
================================================================================

【YOLO类别（2分类）】
0: smoke（烟雾）
1: fire（火焰）

配置文件：configs/yolo_fire.yaml

【LSTM类别（3分类）】
0: Normal（正常）
1: Smoke（烟雾）
2: Fire（火焰）

注意：YOLO和LSTM的类别ID不同！
- YOLO只检测"有没有火/烟"
- LSTM判断"是无火/烟雾/火焰"


================================================================================
4. 8维特征向量
================================================================================

特征提取器从YOLO检测结果中提取8个特征：

1. cx_norm      - 中心点x坐标（归一化到[0,1]）
2. cy_norm      - 中心点y坐标（归一化到[0,1]）
3. w_norm       - 宽度（归一化）
4. h_norm       - 高度（归一化）
5. area_norm    - 面积（归一化）
6. aspect_ratio - 宽高比（w/h）
7. conf         - YOLO置信度
8. cls          - 类别ID（0=smoke, 1=fire）

代码实现：emberguard/feature_extractor.py

举例说明：
```
YOLO检测到一个火焰：
- 边界框：[100, 200, 300, 400]
- 置信度：0.85
- 类别：fire (1)

特征提取器转换为：
[0.5, 0.3, 0.2, 0.15, 0.03, 1.33, 0.85, 1]
 ↑    ↑    ↑    ↑     ↑     ↑     ↑    ↑
 cx   cy   w    h   area  ratio conf cls
```


================================================================================
5. LSTM模型架构
================================================================================

输入层: (batch, 30, 8)
    ↓
LSTM层1: 128个隐藏单元, return_sequences=True
    ↓
Dropout: 0.3
    ↓
LSTM层2: 64个隐藏单元, return_sequences=False
    ↓
Dropout: 0.3
    ↓
全连接层1: 64个神经元, ReLU激活
    ↓
Dropout: 0.3
    ↓
全连接层2: 3个神经元, Softmax激活
    ↓
输出: (batch, 3) - [P(无火), P(烟雾), P(火焰)]

参数量：211,203个
模型大小：~850KB
代码实现：emberguard/lstm_model.py


================================================================================
6. 完整训练流程
================================================================================

--------------------------------------------------------------------------------
6.1 步骤1：训练YOLO
--------------------------------------------------------------------------------

文件：scripts/1_train_yolo.py

【目的】
让YOLO学会识别火和烟

【训练数据】
- D-Fire数据集：21,527张图片
- 每张图片都标注了火焰/烟雾的位置

【代码逻辑】
```python
# 给YOLO看21,527张图片，教它认识火和烟
model = YOLO("models/yolov8n.pt")  # 预训练模型
model.train(
    data="configs/yolo_fire.yaml",  # 指向D-Fire数据集
    epochs=50,                       # 训练50轮
    batch=48                         # 每次看48张
)
```

【YOLO学到了什么】
- 看到红色火焰 → 这是"fire"
- 看到灰色烟雾 → 这是"smoke"
- 看到其他东西 → 不报警

【输出结果】
- runs/detect/train2/weights/best.pt（训练好的YOLO模型）
- 模型大小：~6MB

✅ 这一步完成后，YOLO已经会识别火和烟了！


--------------------------------------------------------------------------------
6.2 步骤2：用YOLO提取特征
--------------------------------------------------------------------------------

文件：scripts/3_prepare_lstm_data.py

【为什么需要这一步】
- LSTM不能直接看图片，只能看数字
- 需要YOLO把图片转换成数字特征

【代码逻辑】
```python
class LSTMDataPreparer:
    def __init__(self):
        # 加载已经训练好的YOLO模型
        self.yolo_model = YOLO('runs/detect/train2/weights/best.pt')
        self.feature_extractor = FeatureExtractor()
    
    def extract_features_from_video(self, video_path):
        """让YOLO看视频，记录每一帧的检测结果"""
        cap = cv2.VideoCapture(video_path)
        features_list = []
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # 1. YOLO检测这一帧
            results = self.yolo_model(frame)
            
            # 2. 把检测结果转换成8个数字
            features = self.feature_extractor.get_best_detection(results)
            # features = [cx, cy, w, h, area, ratio, conf, cls]
            
            features_list.append(features)
        
        return features_list
```

【举例说明】
```
视频1: fire_001.mp4（火灾视频，100帧）

YOLO逐帧检测：
  帧1:  [0.5, 0.3, 0.2, 0.15, 0.03, 1.33, 0.85, 1] ← 检测到火
  帧2:  [0.51, 0.31, 0.21, 0.16, 0.034, 1.31, 0.86, 1] ← 火在扩大
  帧3:  [0.52, 0.32, 0.22, 0.17, 0.037, 1.29, 0.87, 1]
  ...
  帧100: [0.7, 0.5, 0.35, 0.25, 0.088, 1.4, 0.92, 1] ← 火势很大

结果：得到100个特征向量
```


--------------------------------------------------------------------------------
6.3 步骤3：制作LSTM训练样本
--------------------------------------------------------------------------------

【为什么需要滑动窗口】
- LSTM需要看"连续30帧"的变化趋势
- 一个100帧的视频可以切成71个训练样本

【代码逻辑】
```python
def create_sequences(self, features_list, label):
    """把100帧的特征，切成多个30帧的序列"""
    sequences = []
    labels = []
    
    # 滑动窗口：每次取30帧
    for i in range(len(features_list) - 30 + 1):
        seq = features_list[i:i + 30]  # 取30帧
        sequences.append(seq)
        labels.append(label)  # 这个视频的标签（2=火灾）
    
    return sequences, labels
```

【举例说明】
```
100帧特征 → 切成71个训练样本

样本1:  帧[1-30]   → 标签: 火灾
样本2:  帧[2-31]   → 标签: 火灾
样本3:  帧[3-32]   → 标签: 火灾
...
样本71: 帧[71-100] → 标签: 火灾

为什么这样切？
- 让LSTM学习"连续30帧的变化趋势"
- 一个视频能生成很多训练样本（数据增强）
- 相邻样本有重叠，保持时序连续性
```

【处理240个视频后的结果】
```
总共得到：1,259,680个训练样本
每个样本：30帧 × 8维特征 = (30, 8)矩阵
标签分布：
  - 无火（0）: 599,533个样本 (47.6%)
  - 烟雾（1）: 573,681个样本 (45.5%)
  - 火灾（2）: 86,466个样本 (6.9%)

保存为：
  - datasets/lstm_data/sequences.npy: (1259680, 30, 8)
  - datasets/lstm_data/labels.npy: (1259680,)
  - datasets/lstm_data/metadata.json
```


--------------------------------------------------------------------------------
6.4 步骤4：训练LSTM
--------------------------------------------------------------------------------

文件：scripts/4_train_lstm.py

【代码逻辑】
```python
# 加载准备好的数据
sequences = np.load('datasets/lstm_data/sequences.npy')  # (1259680, 30, 8)
labels = np.load('datasets/lstm_data/labels.npy')        # (1259680,)

# 创建LSTM模型
model = LSTMFireClassifier(
    input_size=8,      # 每帧8个特征
    hidden_size=128,   # LSTM隐藏层大小
    num_layers=2,      # 2层LSTM
    num_classes=3      # 3个类别（无火、烟雾、火灾）
)

# 训练LSTM
for epoch in range(50):
    for batch in train_loader:
        sequences_batch, labels_batch = batch  # (32, 30, 8), (32,)
        
        # LSTM看这32个序列，学习判断
        predictions = model(sequences_batch)
        
        # 计算预测错误，调整模型
        loss = criterion(predictions, labels_batch)
        loss.backward()
        optimizer.step()
```

【LSTM学到了什么】
```
学习样本1（火灾）:
  帧1-30: 火焰持续出现，面积逐渐扩大
  → LSTM学会：这种模式是"火灾"

学习样本2（打火机）:
  帧1-3: 有火焰
  帧4-30: 无火焰
  → LSTM学会：这种模式是"无火"（瞬间火光）

学习样本3（烟雾）:
  帧1-30: 烟雾持续出现，但面积不扩大，随后可能扩大
  → LSTM学会：这种模式是"烟雾"
```

【训练参数】
- 批次大小：32
- 训练轮数：50 epochs
- 学习率：0.001
- 优化器：Adam
- 损失函数：Focal Loss（gamma=2.5）
- 类别权重：Normal(0.8x), Smoke(1.0x), Fire(3.5x)
- 学习率调度：每10个epoch降低50%

【输出结果】
- models/lstm/best.pt（训练好的LSTM模型）
- models/lstm/last.pt（最终模型）
- models/lstm/history.json（训练历史）
- 模型大小：~850KB

✅ 训练完成后，LSTM学会了分析时序趋势！


================================================================================
7. 推理阶段
================================================================================

文件：emberguard/pipeline.py

【初始化检测管道】
```python
class FireDetectionPipeline:
    def __init__(self):
        # 加载两个训练好的模型
        self.yolo_model = YOLO('runs/detect/train2/weights/best.pt')
        self.lstm_model = load_model('models/lstm/best.pt')
        
        # 准备一个记忆缓冲区（记住最近30帧）
        self.feature_buffer = deque(maxlen=30)
        self.feature_extractor = FeatureExtractor()
```

【检测单帧画面】
```python
def detect_frame(self, frame):
    """检测一帧画面"""
    
    # 步骤1: YOLO检测当前帧
    results = self.yolo_model(frame)
    
    # 步骤2: 提取8维特征
    features = self.feature_extractor.get_best_detection(results, frame.shape)
    # features = [cx, cy, w, h, area, ratio, conf, cls]
    
    # 步骤3: 把特征加入缓冲区（自动滑动）
    self.feature_buffer.append(features)
    # 现在缓冲区有最近30帧的特征
    
    # 步骤4: 如果缓冲区满了（有30帧），让LSTM分析
    if len(self.feature_buffer) == 30:
        sequence = np.array(list(self.feature_buffer))  # (30, 8)
        pred_class, probs = self.lstm_model.predict(sequence)
        
        return {
            'yolo_detections': [...],      # YOLO的检测框
            'lstm_prediction': pred_class,  # LSTM类别（0/1/2）
            'lstm_class_name': '火焰',     # 类别名称
            'lstm_confidence': probs[pred_class],  # 置信度
            'lstm_probabilities': {        # 概率分布
                '无火': probs[0],
                '烟雾': probs[1],
                '火焰': probs[2]
            }
        }
```

【实时检测流程示例】
```
视频流输入（每秒30帧）

帧1  → YOLO检测 → 特征 → 缓冲区[1帧]    → 输出：YOLO结果
帧2  → YOLO检测 → 特征 → 缓冲区[2帧]    → 输出：YOLO结果
帧3  → YOLO检测 → 特征 → 缓冲区[3帧]    → 输出：YOLO结果
...
帧29 → YOLO检测 → 特征 → 缓冲区[29帧]   → 输出：YOLO结果
帧30 → YOLO检测 → 特征 → 缓冲区[30帧] ✅ 满了！
     → LSTM分析帧[1-30]
     → 输出：YOLO结果 + LSTM预测（火灾 80%）

帧31 → YOLO检测 → 特征 → 缓冲区[30帧]（帧1被丢弃）
     → LSTM分析帧[2-31]
     → 输出：YOLO结果 + LSTM预测（火灾 82%）

帧32 → YOLO检测 → 特征 → 缓冲区[30帧]（帧2被丢弃）
     → LSTM分析帧[3-32]
     → 输出：YOLO结果 + LSTM预测（火灾 85%）

...持续检测
```

【滑动窗口缓冲机制】
使用Python的deque（双端队列）实现：
```python
from collections import deque

# 创建固定长度的队列
self.feature_buffer = deque(maxlen=30)

# 添加新元素时，如果队列满了，自动丢弃最老的元素
self.feature_buffer.append(new_feature)
```

优势：
- 自动维护最新30帧
- 内存占用固定（~1KB）
- 高效的添加/删除操作


================================================================================
8. 关键问题解答
================================================================================

【Q1：视频不满30帧怎么办？】
A：前29帧只有YOLO检测，无LSTM预测。第30帧开始才有LSTM结果。

详细说明：
```
帧1:  YOLO检测 → 缓冲区[1帧]  → 无LSTM预测
帧2:  YOLO检测 → 缓冲区[2帧]  → 无LSTM预测
...
帧29: YOLO检测 → 缓冲区[29帧] → 无LSTM预测
帧30: YOLO检测 → 缓冲区[30帧] → ✅ 首次LSTM预测
```

【Q2：推理是1-30,31-60还是1-30,2-31？】
A：是1-30, 2-31, 3-32...（滑动窗口，每次移动1帧）

使用deque(maxlen=30)实现自动滑动：
```
帧30: 缓冲区[1-30]   → LSTM分析
帧31: 缓冲区[2-31]   → LSTM分析（帧1自动被移除）
帧32: 缓冲区[3-32]   → LSTM分析（帧2自动被移除）
```

优点：
- 每帧都会触发LSTM预测（从第30帧开始）
- 能捕捉细微变化
- 响应及时

【Q3：前面30帧会被忘记吗？】
A：是的。LSTM只记住最近30帧（约1秒），这是设计特性。

原因：
1. 火灾检测需要关注当前状态
2. 30帧（1秒）足够判断趋势
3. 避免历史干扰（火已扑灭但仍报警）
4. 降低计算复杂度

【Q4：为什么要分别训练YOLO和LSTM？】
A：
- 任务不同：YOLO学空间检测，LSTM学时序分析
- 数据不同：YOLO用图片，LSTM用特征序列
- 结构不同：YOLO是CNN，LSTM是RNN


================================================================================
9. 数据流动
================================================================================

【训练阶段完整流程】
```
步骤1: 训练YOLO
输入: 21,527张图片（D-Fire数据集）
处理: 卷积神经网络学习识别火和烟
输出: runs/detect/train2/weights/best.pt（~6MB）

步骤2: 用YOLO提取特征
输入: 240个视频（火灾、烟雾、正常场景）
处理: YOLO逐帧检测 → 提取8维特征向量
输出: 每个视频的特征序列

步骤3: 制作LSTM训练数据
输入: 240个视频的特征序列
处理: 滑动窗口切分（30帧一组）
输出: 1,259,680个训练样本（sequences.npy + labels.npy）

步骤4: 训练LSTM
输入: 1,259,680个序列 + 标签
处理: LSTM网络学习时序模式
输出: models/lstm/best.pt（~850KB）
```

【推理阶段完整流程】
```
实时视频流（每秒30帧）
    ↓
每一帧处理：
1. YOLO检测当前帧
   输入: 一张图片 (H×W×3)
   输出: 检测框 + 置信度 + 类别

2. 提取8维特征
   输入: YOLO检测结果
   输出: [cx, cy, w, h, area, ratio, conf, cls]

3. 加入缓冲区
   操作: feature_buffer.append(features)
   状态: 保持最新30帧
    ↓
当缓冲区满30帧时：
4. LSTM分析趋势
   输入: 30帧特征序列 (30, 8)
   输出: 3个概率 [无火, 烟雾, 火焰]

5. 输出最终结果
   - YOLO检测框（空间信息）
   - LSTM判断（时序分析）
   - 综合置信度
```

【数据维度变化】
训练阶段：
```
图片 (640, 640, 3)
  ↓ YOLO检测
特征向量 (8,)
  ↓ 收集30帧
序列 (30, 8)
  ↓ 批次训练
批次 (32, 30, 8)
  ↓ LSTM处理
输出 (32, 3)
```

推理阶段：
```
视频帧 (H, W, 3)
  ↓ YOLO检测
特征向量 (8,)
  ↓ 缓冲区收集
序列 (30, 8)
  ↓ 添加批次维度
批次 (1, 30, 8)
  ↓ LSTM预测
输出 (1, 3)
  ↓ 取最大值
最终类别 (1,)
```


================================================================================
10. 完整工具链
=====================================================================

【数据准备】
scripts/2.1_organize_downloaded_data.py - 整理数据集
scripts/2.2_test_feature_extraction.py - 测试特征提取

【模型训练】
scripts/1_train_yolo.py - 训练YOLO
scripts/2_validate_yolo.py - 验证YOLO
scripts/3_prepare_lstm_data.py - 准备LSTM数据
scripts/4_train_lstm.py - 训练LSTM

【模型测试】
scripts/5_run_gui.py - GUI（纯YOLO）
scripts/6_test_lstm.py - 测试LSTM
scripts/7_quick_test.py - 快速测试
scripts/8_detect_with_lstm.py - YOLO+LSTM检测
scripts/9_compare_yolo_lstm.py - 对比测试


================================================================================
11. 高级特性
================================================================================

【PostProcessor后处理模块】
文件：emberguard/post_processor.py
功能：
- 分析检测序列的趋势和模式
- 检测火灾发展趋势（烟雾→火焰）
- 计算综合置信度
- 提供更智能的判断逻辑

【训练高级特性】
- 断点续训：--resume参数，从checkpoint继续
- Focal Loss：处理类别不平衡，gamma=2.5
- 类别权重：Normal(0.8x), Smoke(1.0x), Fire(3.5x)
- 学习率调度：每10个epoch降低50%
- 定期测试：--test_intepoch测试
- 自动目录管理：train, train2, train3...


================================================================================
12. 核心代码位置
================================================================================

【核心模块】
emberguard/feature_extractor.py - 特征提取器
emberguard/lstm_model.py - LSTM模型
emberguard/pipeline.py - 检测管道
emberguard/post_processor.py - 后处理分析器

【配置文件】
configs/yolo_fire.yaml - YOLO数据集配置
configs/ultralytics_settings.json - Ultralytics设置

【数据目录】
datasets/D-Fire/ - YOLO训练数据（21,527张图片）
datasets/fire_videos_organized/ - LSTM训练数据（240个视频）
  ├── fire/ - 48个火灾视频
  ├── smoke/ - 92个烟雾视频
  ├── normal/ - 100个正常视频
  └── mixed/ - 4个测试视频
datasets/lstm_data/ - LSTM训练样本（1,259,680个序列）

【模型文件】
runs/detect/train2/weights/best.pt - YOLO模型（~6MB）
models/lstm/best.pt - LSTM模型（~800KB）


================================================================================
13. 技术创新点
================================================================================

1. 两阶段级联架构
   - YOLO空间检测 + LSTM时序分析
   - 结合空间和时间信息
   - 优势互补

2. Focal Loss损失函数
   - 解决类别不平衡问题
   - 自动关注难分类样本（Fire类别）
   - 训练更稳定

3. 滑动窗口机制
   - 充分利用时序信息
   - 数据增强效果（1个视频→71个样本）
   - 实时推理友好（每帧都预测）

4. 8维精简特征
   - 高效实时（只需8个数字）
   - 归一化处理（数值稳定）
   - 包含空间和语义信息


================================================================================
14. 总结
================================================================================

【架构本质】
YOLO+LSTM = 空间检测 + 时序分析

┌──────────────┐      ┌──────────────┐
│   YOLO       │  →   │    LSTM      │
│  (眼睛)      │      │   (大脑)     │
│              │      │              │
│ 看单帧图片   │      │ 看30帧趋势   │
│ 识别火/烟    │      │ 判断真假     │
└──────────────┘      └──────────────┘

【关键机制】
1. 滑动窗口：1-30, 2-31, 3-32...（每帧移动1帧）
2. 实时分析：每帧都有结果（从第30帧开始）
3. 短期记忆：只记住最近30帧（约1秒）
4. 自动维护：deque(maxlen=30)自动管理缓冲区

【设计优势】
✅ 实时性好：每帧都分析
✅ 准确率高：时序信息帮助判断
✅ 误报率低：不会被单帧误检影响
✅ 计算高效：只需要30帧的缓冲区
✅ 工具完善：13个脚本覆盖全流程
✅ 可视化强：对比图表清晰展示LSTM优势

【关键理解】
1. 两个独立的模型
   - YOLO：已训练完成（runs/detect/train2/weights/best.pt）
   - LSTM：需要单独训练（models/lstm/best.pt）

2. YOLO是工具
   - 在LSTM训练时：用来提取特征（参数冻结）
   - 在推理时：用来检测每一帧（参数冻结）
   - YOLO本身不需要重新训练

3. LSTM是核心
   - 学习"什么样的时序模式是真火灾"
   - 需要用YOLO提取的特征来训练
   - 训练数据：1,259,680个序列

4. 协作方式
   - 串联工作：YOLO先检测 → LSTM再分析
   - 各自独立：两个模型参数互不影响
   - 优势互补：YOLO快速 + LSTM准确

【适用场景】
✅ 实时监控系统
✅ 视频流分析
✅ 边缘设备部署
✅ 离线视频处理
✅ 任何需要时序分析的检测任务

推广应用：
- 暴力行为检测
- 异常行为检测
- 交通事故检测
- 工业异常检测


================================================================================
参考资料
================================================================================

【项目文档】
- README.md - 项目概述
- PROJECT_GUIDE.md - 项目指南
- DEVELOPMENT_LOG.md - 开发日志
- docs/TECHNICAL_RESEARCH.md - 技术研究报告

【模块文档】
- emberguard/README.md - LSTM模块文档
- scripts/README.md - 脚本文档
- UI/README.md - GUI文档

【数据集】
- D-Fire数据集：21,527张图片
- 视频数据集：240个视频


================================================================================
文档结束
================================================================================
